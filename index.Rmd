---
title: "Tidy data structures and visualisation <br> to support exploration and modeling of temporal-context data"
type: "seminar"
author: "Earo Wang"
date: "Mar 14, 2018 <br> slides at <http://slides.earo.me/phd18>"
output:
  xaringan::moon_reader:
    css: ["default", "myremark.css", "timeline.css"]
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r initial, echo = FALSE, cache = FALSE, results = 'hide'}
library(knitr)
options(htmltools.dir.version = FALSE, tibble.width = 60, tibble.print_min = 6)
opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, comment = "#>",
  fig.path = 'figure/', cache.path = 'cache/', fig.align = 'center', 
  fig.width = 12, fig.height = 11, fig.show = 'hold', 
  cache = TRUE, external = TRUE, dev = 'svglite'
)
read_chunk('src/code.R')
```

```{r load-pkgs}
```

```{r theme-remark}
```

class: middle

## Agenda

* **WIP**: Tidy data structures to support exploration and modeling of temporal-context data (chapter 3)
* **Done**: Calendar-based graphics for visualising people’s daily schedules (chapter 2)
* **ToDo**: Visualisation of time series with nested and crossed factors (chapter 4)

???

* First, I'll spend most of the time talking about
* Then, I'll briefly review my first-year work
* Finally,

---

background-image: url(figure/map-airlines-1.svg)
background-size: cover

class: bottom center

```{r map-airlines, fig.width = 13, eval = FALSE}
```

# USA airline traffic in 2016 & 2017

*data source: [US Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236)*

???

* as usual, the data comes first.
* last year, I looked at the foot traffic
* The first sight of this map is a bit overwhelming I suppose, but the main message is there are a few hubs and sporadic airports.

---

background-image: url(img/data-snapshot.png)
background-size: cover

class: inverse bottom center

# Data snapshot

???

* This dataset is actually about the on-time performance for each flight at its scheduled departure time.
* There are 11m obs.
* It's not that big but bigish.

---

.pull-left[
* heterogeneous data types
* fine scale time resolution
]
.pull-right[
* multiple measured variables
* multiple grouping variables
]
.center[<img src="img/data-snapshot.png" height=460px>]

???

* as you can see, this dataset is quite rich with lots of information.
* it features

---

## However ...

--

The current structure that underlies time series objects:

\begin{equation}
  \begin{bmatrix}
  X_{11} & X_{21} & \cdots & X_{p1} \\
  X_{12} & X_{22} & \cdots & X_{p2} \\
  \vdots & \vdots & \ddots & \vdots \\
  X_{1T} & X_{2T} & \cdots & X_{pT}
  \end{bmatrix}
\end{equation}

where $X_{jt}$ represents series $j$, for $j = 1, \dots, p$ and $1 \leq t \leq T$, in the form of a $T \times p$ matrix.

--

This matrix structure requires

* homogeneity (numerical variables)
* time indices implicitly inferred as attributes/meta-information

It is **model-centric** rather than **data-centric**.

???

it's a bit frustrating to work with this kind of temporal data.

---

class: middle

## The matrix structure

.x[
* discards interesting information in the data;
* is implicit not explicit in handling of the temporal components;
* fails to support transparent workflow.
]

???

* if we actually put the data into the matrix container, we would throw away lots of interesting pieces.
* more opaque in dealing with temporal components
* and therefore it leads to non-transparent workflow 

not transparent (leading to mistakes)

---

class: middle

## Non-transparent workflow

.pull-left[
```{r echo = TRUE, eval = FALSE}
for (...) {
  if (...) {
    ...
  } else {
    ...
  }
  for (...) {
  }
}
...
for (...) {
  if (...) {
    ...
  } else {
    ...
  }
  for (...) {
  }
}
```
]

--

.pull-right[
.shake[<img src="img/duang.png" size=50%>]
> Where I'm doing wrong?

> What I'm doing?
]

---

class: middle

## Instead, we'd like

.checked[
* heterogeneous data types to keep the richness of data
* an explicitly declared index variable to be easily accessible
* a syntactical approach to express nested or crossed factors
* data pipelines to facilitate the workflow
]

???



---

class: inverse middle center

.scale-up[<img src="img/tsibble.svg" height=200px size=50%>]

## Chinglish for time series tibble

---

class: inverse middle center

<img src="img/tsibble.svg" height=200px size=50%>

## ~~Chinglish for time series tibble~~
## The future of time series in R

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
]
.right-column[
.large[Tidy data principles.red[<sup>1</sup>]:]
* Each variable forms a column.
* Each observation forms a row.
* Each type of observational unit forms a table.
<!--
.center[<img src="img/tidy.png" height=130px>]
-->
]

.footnote[
.red[1.] Wickham, H (2014). Tidy data. Journal of Statistical Software 59(10), 1–23.
]

???

There are three interrelate rules to make a dataset tidy.

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
]
.right-column[
.large[Tidy data principles.red[<sup>1</sup>]:]
* Each variable forms a column.
* Each observation forms a row.
* Each type of observational unit forms a table.

.center[`r icon::fa("plus")`]

.large[Tidy temporal data:]
* **index**: an explicitly declared variable containing time indices.red[<sup>2</sup>].
* **key**: uniquely identifies each unit that measurements take place on over time.
* **interval**: a common time interval if data with regular time interval.
]

.footnote[
.red[1.] Wickham, H (2014). Tidy data. *Journal of Statistical Software* **59**(10), 1–23. <br>
.red[2.] Grolemund, G. & Wickham, H. (2011). Dates and times made easy with lubridate. *Journal of Statistical Software*, **40**(3), 1–25.
]

???

* three additional info:
* index forms the contextual base of the temporal data
* key + index = primary key in the SQL database

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
]
.right-column[
```{r load-data, cache.lazy = FALSE, eval = FALSE}
```

```{r tsibble, cache.lazy = FALSE, eval = FALSE}
```

```{r echo = TRUE, eval = FALSE}
flights %>% 
  as_tsibble(
    key = id(flight), 
    index = sched_dep_datetime, 
    regular = FALSE
  )
```

```
*#> # A tsibble: 11,076,746 x 27 [!]
*#> # Keys:      flight [24,647]
#>    flight sched_dep_datetime  dep_time sched_dep_time
#>    <chr>  <dttm>                 <int>          <int>
#>  1 AA1    2016-01-01 09:00:00      856            900
#>  2 AA1    2016-01-02 09:00:00      857            900
#>  3 AA1    2016-01-03 09:00:00      913            900
#>  4 AA1    2016-01-04 09:00:00      903            900
#>  5 AA1    2016-01-05 09:00:00      850            900
#>  6 AA1    2016-01-06 09:00:00      855            900
#> # ... with 11,076,740 more rows, and 23 more variables:
#> #   dep_delay <dbl>, arr_time <int>, sched_arr_time <int>,
#> #   arr_delay <dbl>, carrier <chr>, tailnum <chr>,
#> #   origin <chr>, dest <chr>, air_time <dbl>,
#> #   distance <dbl>, origin_city_name <chr>,
#> #   origin_state <chr>, origin_state_name <chr>,
#> #   dest_city_name <chr>, dest_state <chr>,
#> #   dest_state_name <chr>, taxi_out <dbl>, taxi_in <dbl>,
#> #   carrier_delay <dbl>, weather_delay <dbl>,
#> #   nas_delay <dbl>, security_delay <dbl>,
#> #   late_aircraft_delay <dbl>
```
]

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
]
.right-column[
An explicitly declared variable (e.g. `sched_dep_datetime`) which could contain:
* date-time: 
```{r}
seq(ymd_hm("2018-03-14 16:00"), by = "15 mins", length.out = 2)
```
* date:
```{r}
seq(ymd("2018-03-13"), by = 1, length.out = 2)
```
* year-month:
```{r}
yearmonth(seq(2018, by = 1 / 12, length.out = 2))
```
* year-quarter:
```{r}
yearquarter(seq(2018, by = 1 / 4, length.out = 2))
```
* year:
```{r}
seq(2017, by = 1, length.out = 2)
```
* and etc.
]

???

* the index variable is being declared explictly
* extensible to trading days
* why the explicit time indices turn out useful, the use case would be join the flight data with other tables, e.g. weather data based on the same timestamps.
* impossible for implicit time index

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
### - key
]
.right-column[
Uniquely identifies each unit that measurements take place on over time:
* single: 
```{r, echo = TRUE, eval = FALSE}
id(flight)
```
* nested:
```{r, echo = TRUE, eval = FALSE}
id(origin | origin_city | origin_state)
```
* crossed:
```{r, echo = TRUE, eval = FALSE}
id(origin, dest)
```
* nested & crossed:
```{r, echo = TRUE, eval = FALSE}
id(origin | origin_state, dest | dest_state)
```
]

???

* The key could include a single or multiple columns
* for example, sufficient to use flight to identify units
* if the key consists of multiple vars, we need to consister they are nested or crossed.
* e.g. a nesting structure in this case is the origin nested within the city | state. The ordering from lower to higher, using the vertical bar to describe the nesting

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
### - key
### - why tsibble?
]
.right-column[
.center[.large[I. flexible]]

<br>
<br>
.center[<img src="img/melt.png">]
]

???

* why tsibble is useful?
* we are unable to recover this original dataset from this matrix, as it's a case of simplicity and doesn't accommodate actual datasets with rich info

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
### - key
### - why tsibble?
]
.right-column[
.center[.large[II. mapping from data semantics to its physical layout]]

.center[<img src="img/semantics.png">]
]

???

* variables are in columns, observations are in rows, and values are in cells.
* Every value belongs to a variable and an observation
* A variable contains all values that measure the same underlying attribute across units over time. 
* An observation contains all values measured on the same unit at a time point across attributes.

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
### - key
### - why tsibble?
]
.right-column[
.center[.large[III. WYTIWYC]]

`r emo::ji("one")` select variables `flight`, `sched_dep_datetime`, `dep_delay`

```{r select, echo = TRUE, cache.lazy = FALSE, eval = FALSE}
```

```
#> # A tsibble: 11,076,746 x 3 [!]
#> # Keys:      flight [24,647]
#>   flight sched_dep_datetime  dep_delay
#>   <chr>  <dttm>                  <dbl>
#> 1 AA1    2016-01-01 09:00:00       -4.
#> 2 AA1    2016-01-02 09:00:00       -3.
#> 3 AA1    2016-01-03 09:00:00       13.
#> 4 AA1    2016-01-04 09:00:00        3.
#> 5 AA1    2016-01-05 09:00:00      -10.
#> 6 AA1    2016-01-06 09:00:00       -5.
#> # ... with 1.108e+07 more rows
```

.center[<img src="img/select.png" height=150>]
]

???

this mapping property takes us to what you think is what you code

* operating on the columns

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
### - key
### - why tsibble?
]
.right-column[
.center[.large[III. WYTIWYC]]

`r emo::ji("two")` filter observations for 2017

```{r filter, echo = TRUE, cache.lazy = FALSE, eval = FALSE}
```

```
#> # A tsibble: 5,560,846 x 3 [!]
#> # Keys:      flight [22,563]
#>   flight sched_dep_datetime  dep_delay
#>   <chr>  <dttm>                  <dbl>
#> 1 AA1    2017-01-01 08:00:00       31.
#> 2 AA1    2017-01-02 08:00:00       -3.
#> 3 AA1    2017-01-03 08:00:00       -6.
#> 4 AA1    2017-01-04 08:00:00       -3.
#> 5 AA1    2017-01-05 08:00:00       -7.
#> 6 AA1    2017-01-06 08:00:00       -3.
#> # ... with 5.561e+06 more rows
```

.center[<img src="img/filter.png" height=150>]
]

???

* perform the operations on the rows

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
### - key
### - why tsibble?
]
.right-column[
.center[.large[III. WYTIWYC]]

`r emo::ji("three")` aggregate to monthly averages

```{r tsum, echo = TRUE, cache.lazy = FALSE, eval = FALSE}
```

```
#> # A tsibble: 12 x 2 [1MONTH]
#>       yrmth avg_delay
#>       <mth>     <dbl>
#>  1 2017 Jan     12.1 
#>  2 2017 Feb      7.10
#>  3 2017 Mar      9.28
#>  4 2017 Apr     12.1 
#>  5 2017 May     10.8 
#>  6 2017 Jun     13.6 
#>  7 2017 Jul     13.1 
#>  8 2017 Aug     11.1 
#>  9 2017 Sep      5.25
#> 10 2017 Oct      6.64
#> 11 2017 Nov      4.26
#> 12 2017 Dec      9.89
```

]

???

* You can see this process is very intuitive. You have a well-organised dataset and you think the verb to work on either variables or observations and you have the code already.

---

.left-column[
<img src="img/tsibble.svg" height=120px>
### - definition
### - index
### - key
### - why tsibble?
]
.right-column[
.center[.large[IV. verbs]]

A consistent set of verbs to solve a wide range of temporal data transformation problems:

* row-wise: `filter()`, `slice()`, `arrange()`, `fill_na()`
* column-wise: `mutate()`, `select()`, `summarise()`, `tsummarise()`

These all naturally work with `group_by()`.

* join two tables: `left_join()`, `right_join()`, `full_join()`, `semi_join()`, `anti_join()`
* rolling window: `slide()`, `tile()`, `stretch()`
]

---

class: inverse middle center

## Data pipelines
### break up a big problem into smaller pieces

.footnote[
.red[*] Buja, A., Asimov, D., Hurley G., & McDonald J. (1988) Elements of a viewing piepline for data analysis. <br>
.red[*] Wickham, H., Lawrence, M., Cook, D. et al. (2009) The plumbing of interactive graphics. *Computational Statistics* **(24)**207
]

???

The tidy time series structure also supports thinking of operations on the data as part of a data pipeline

---

## Question

Do time of the day and day of the week affect the on-time performance in 2017?

--

```{r delayed-facet, fig.height = 9}
```

---

## Pipeline I

.block[
.flowchart[
* `filter()` <br> subset time window
]
]

```{r, echo = TRUE, eval = FALSE}
n_flights <- flights %>% 
* filter(year(sched_dep_datetime) == 2017) %>% 
  mutate(dep_delay_break = case_when(
    dep_delay <= 15 ~ "ontime",
    dep_delay <= 60 ~ "15-60 mins",
    TRUE ~ "60+ mins"
  )) %>% 
  group_by(dep_delay_break) %>% 
  tsummarise(
    floor_date(sched_dep_datetime, unit = "hour"), 
    n_flight = n()
  ) %>% 
  mutate(
    hour = hour(sched_dep_datetime),
    date = as_date(sched_dep_datetime),
    wday = wday(sched_dep_datetime, label = TRUE, week_start = 1)
  )
```

---

## Pipeline I

.block[
.flowchart[
* `filter()` <br> subset time window
* `mutate()` <br> create a new variable
]
]

```{r, echo = TRUE, eval = FALSE}
n_flights <- flights %>% 
  filter(year(sched_dep_datetime) == 2017) %>% 
* mutate(dep_delay_break = case_when(
*   dep_delay <= 15 ~ "ontime",
*   dep_delay <= 60 ~ "15-60 mins",
*   TRUE ~ "60+ mins"
* )) %>% 
  group_by(dep_delay_break) %>% 
  tsummarise(
    floor_date(sched_dep_datetime, unit = "hour"), 
    n_flight = n()
  ) %>% 
  mutate(
    hour = hour(sched_dep_datetime),
    date = as_date(sched_dep_datetime),
    wday = wday(sched_dep_datetime, label = TRUE, week_start = 1)
  )
```

---

## Pipeline I

.block[
.flowchart[
* `filter()` <br> subset time window
* `mutate()` <br> create a new variable
* `tsummarise()` <br> aggregate to hourly intervals
]
]

```{r, echo = TRUE, eval = FALSE}
n_flights <- flights %>% 
  filter(year(sched_dep_datetime) == 2017) %>% 
  mutate(dep_delay_break = case_when(
    dep_delay <= 15 ~ "ontime",
    dep_delay <= 60 ~ "15-60 mins",
    TRUE ~ "60+ mins"
  )) %>% 
* group_by(dep_delay_break) %>% 
* tsummarise(
*   floor_date(sched_dep_datetime, unit = "hour"), 
*   n_flight = n()
* ) %>% 
  mutate(
    hour = hour(sched_dep_datetime),
    date = as_date(sched_dep_datetime),
    wday = wday(sched_dep_datetime, label = TRUE, week_start = 1)
  )
```

---

## Pipeline I

.block[
.flowchart[
* `filter()` <br> subset time window
* `mutate()` <br> create a new variable
* `tsummarise()` <br> aggregate to hourly intervals
* `mutate()` <br> augment time units
]
]

```{r, echo = TRUE, eval = FALSE}
n_flights <- flights %>% 
  filter(year(sched_dep_datetime) == 2017) %>% 
  mutate(dep_delay_break = case_when(
    dep_delay <= 15 ~ "ontime",
    dep_delay <= 60 ~ "15-60 mins",
    TRUE ~ "60+ mins"
  )) %>% 
  group_by(dep_delay_break) %>% 
  tsummarise(
    floor_date(sched_dep_datetime, unit = "hour"), 
    n_flight = n()
  ) %>% 
* mutate(
*   hour = hour(sched_dep_datetime),
*   date = as_date(sched_dep_datetime),
*   wday = wday(sched_dep_datetime, label = TRUE, week_start = 1)
* )
```

---

```{r n-flights-2017, echo = TRUE, cache.lazy = FALSE, eval = FALSE}
```

```
*#> # A tsibble: 22,855 x 6 [1HOUR]
*#> # Keys:      dep_delay_break [3]
#>   dep_delay_break sched_dep_datetime  n_flight  hour date       wday 
#>   <chr>           <dttm>                 <int> <int> <date>     <ord>
#> 1 15-60 mins      2017-01-01 00:00:00        3     0 2017-01-01 Sun  
#> 2 15-60 mins      2017-01-01 01:00:00        1     1 2017-01-01 Sun  
#> 3 15-60 mins      2017-01-01 02:00:00        2     2 2017-01-01 Sun  
#> 4 15-60 mins      2017-01-01 05:00:00       14     5 2017-01-01 Sun  
#> 5 15-60 mins      2017-01-01 06:00:00       49     6 2017-01-01 Sun  
#> 6 15-60 mins      2017-01-01 07:00:00       68     7 2017-01-01 Sun  
#> # ... with 2.285e+04 more rows
```
---

## Pipe into the grammar of graphics

```{r echo = TRUE, eval = FALSE}
ggplot(n_flights) +
  geom_line(aes(x = hour, y = n_flight, group = date), alpha = 0.25) +
  geom_line(
    aes(x = hour, y = avg_n_flight, colour = dep_delay_break), 
    data = avg_n_flights,
  ) +
  facet_grid(dep_delay_break ~ wday, scales = "free_y")
```

.center[<img src="figure/delayed-facet-1.svg" height=380px>]

---

background-image: url(img/calendar.png)
background-size: cover

class: inverse center bottom

# Pipeline II: calendar-based visualisation <img src="img/sugrrants.svg" height=120px size=50%>

???

It is quite often to have sub-daily data, but there's no graphic tool for 

---

## Pipeline II: quantiles of departure delay into a calendar layout

.block[
.flowchart[
* `filter()` <br> subset time window
* `tsummarise()` <br> aggregate to hourly intervals
* `mutate()` <br> augment time units
* `frame_calendar()` <br> re-structure into a calendar layout
]
]

```{r delay-qtl-data-pseudo, echo = TRUE, eval = FALSE}
delay_qtl <- flights %>% 
  filter(
    year(sched_dep_datetime) == 2017, 
    hour(sched_dep_datetime) > 4
  ) %>% 
  tsummarise(
    floor_date(sched_dep_datetime, unit = "hour"), 
    qtl50 = quantile(dep_delay, 0.5),
    qtl80 = quantile(dep_delay, 0.8),
    qtl95 = quantile(dep_delay, 0.95)
  ) %>% 
  mutate(
    zero = 0,
    hour = hour(sched_dep_datetime), 
    date = as_date(sched_dep_datetime)
  ) %>% 
* frame_calendar(
*   x = hour, y = vars(qtl95, qtl80, qtl50, zero), date = date,
* )
```

<!--
```
#> # A tsibble: 6,935 x 7 [1HOUR]
#>   sched_dep_datetime  qtl50 qtl80 qtl95  zero  hour date      
#>   <dttm>              <dbl> <dbl> <dbl> <dbl> <int> <date>    
#> 1 2017-01-01 05:00:00   -2.  3.00  29.1    0.     5 2017-01-01
#> 2 2017-01-01 06:00:00   -3.  2.80  39.7    0.     6 2017-01-01
#> 3 2017-01-01 07:00:00   -3.  5.00  51.0    0.     7 2017-01-01
#> 4 2017-01-01 08:00:00   -2.  5.00  46.0    0.     8 2017-01-01
#> 5 2017-01-01 09:00:00   -2.  8.00  57.6    0.     9 2017-01-01
#> 6 2017-01-01 10:00:00   -2. 10.0   75.4    0.    10 2017-01-01
#> # ... with 6,929 more rows
```
-->

---

```{r delay-qtl-cal, fig.height = 8, fig.width = 10}
```
---

class: center

```{r plotly-cal}
```

---

## Pipeline II: calendarise the data

.center[<img src="img/month.png" width = 380>]

The grid position for any day in the month is given by

$$\begin{align}
i &= \lceil (g \mod 35) / 7\rceil \\ j &= g \mod 7.
\end{align}$$

Let $h$ and $q$ be the scaled hour and quantiles, respectively, then the final
coordinates are given by:

$$\begin{align}
x &= j + h \\ y &= i - q.
\end{align}$$

---

class: inverse middle center

# Wrap-up

---

## Data science pipeline

<br>
<br>
<img src="img/data-science.png">

.footnote[adapted from [r4ds](http://r4ds.had.co.nz/explore-intro.html)]

---

.top[<img src="img/tsibble.svg" height=80px>]

## Tidy temporal data

* Rectangular form: heterogeneous data types, multiple measured and grouping variables, implict missing values, and etc.
* An explicitly declared index variable and a set of keys
* A mapping bridging the semantics of a dataset to its physical representation
* A data pipeline that supports thinking of operations on the data variables and observations

.center[<img src="img/semantics.png" height=280>]

---

.top[<img src="img/sugrrants.svg" height=80px>]

## Calendar-based visualisation

* Easily integrated as part of data pipelines
* Synchronise neatly with grammar of graphics
* Patterns on special events more easily pop out to the viewer
* Useful for studying sub-daily time series related to human behaviours

.center[<img src="figure/delay-qtl-cal-1.svg" height=380>]

---

class: inverse middle center

## Visualisation of time series with nested and crossed factors

### student enrolment data: e.g. dept | faculty, campus
### previous modeling work

???


---

.left-column[
## Timeline
### - Done
]
.right-column[
.timeline.timeline-left.timeline-with-arrows[
.timeline-block[
.arrow-right[
.timeline-content[
[**Tidy data and statistical visualisation to support exploration of temporal data with R**](http://slides.earo.me/medascin17/) <br>
Workshop @ Data Science Week, Melbourne
.timeline-date[
2017/05
]]]]
.timeline-block[
.arrow-right[
.timeline-content[
[**Sketch people’s daily schedules**](http://slides.earo.me/wombat17/) <br>
Lightning @ Wombat, Melbourne
.timeline-date[
2017/05
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
sugrrants v0.1.0 CRAN release
.timeline-date[
2017/07
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
[**Calendar-based graphics for visualizing people’s daily schedules**](http://pub.earo.me/calendar-vis.pdf) submitted to JSS
.timeline-date[
2017/08
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
[**Analysing sub-daily time series data**](http://slides.earo.me/meetup17/) <br>
Invited talk @ MelbURN, Melbourne
.timeline-date[
2017/10
]]]]
]
]

---

.left-column[
## Timeline
### - Done
]
.right-column[
.timeline.timeline-left.timeline-with-arrows[
.timeline-block[
.arrow-right[
.timeline-content[
[**Calendar-based graphics for visualizing people’s daily schedules**](http://slides.earo.me/iasc17/) <br>
Contributed talk @ IASC, Auckland
.timeline-date[
2017/12
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
tsibble v0.1.0 CRAN release
.timeline-date[
2018/01
]]]]
.timeline-block[
.arrow-right[
.timeline-content[
**Calendar-based graphics for visualizing people’s daily schedules**
won the 2018 ASA Statistical Graphics Student Paper Award `r emo::ji("trophy")`
.timeline-date[
2018/01
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
[**When time series meets tibble, it’s tsibble!**](http://slides.earo.me/rstudioconf18/tsibble.pdf)
Poster @ rstudio::conf, San Diego
.timeline-date[
2018/01
]]]]
]
]

---

.left-column[
## Timeline
### - Done
### - ToDo
]
.right-column[
.timeline.timeline-left.purple-flirt.timeline-with-arrows[
.timeline-block[
.arrow-right[
.timeline-content[
Academic visit @ Paris & Brussels
.timeline-date[
2018/04
]]]]
.timeline-block[
.arrow-right[
.timeline-content[
**Tidy data structures to support exploration and modeling of temporal-context data**
submitted to JCGS
.timeline-date[
2018/07
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
**Tidy data structures to support exploration and modeling of temporal-context data** <br>
Contributed talk @ UseR!2018, Brisbane
.timeline-date[
2018/07
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
**Calendar-based graphics for visualizing people’s daily schedules** <br>
Contributed talk @ JSM, Vancouver
.timeline-date[
2018/08
]]]]
]
]

---


.left-column[
## Timeline
### - Done
### - ToDo
]
.right-column[
.timeline.timeline-left.purple-flirt.timeline-with-arrows[
.timeline-block[
.arrow-right[
.timeline-content[
**Tidy data structures to support exploration and modeling of temporal-context data** <br>
Contributed talk @ ISCB, Melbourne
.timeline-date[
2018/08
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
**Visualisation of time series with nested and crossed factors**
.timeline-date[
2019/03
]]]]

.timeline-block[
.arrow-right[
.timeline-content[
Thesis `r emo::ji("v")`
.timeline-date[
2019/06
]]]]
]
]

---

class: inverse middle center

## Joint work with Di & Rob

<img src="img/super.jpg" height=420px size=50%>

---

class: inverse middle center

### Made with [`r icon::fa("heart")`]() and .orange[`r icon::fa("coffee")`]

--

### Slides created via xaringan `r emo::ji("crossed_swords")` <http://slides.earo.me/phd18>

--
### Reproducible & open source <https://github.com/earowang/phd18>

--
### This work is under licensed [`r icon::fa("creative-commons")` BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/).

--

### Thank you!

--

### .

--

### .

--

### .

--

### THE END
